{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Convolutional Neural Networks and Computer Vision with TensorFlow\n",
    "\n",
    "So far we've covered the basics of TensorFlow and built a handful of models to work across different problems.\n",
    "\n",
    "Now we're going to get specific and see how a special kind of neural network, [convolutional neural networks (CNNs)](https://en.wikipedia.org/wiki/Convolutional_neural_network) can be used for computer vision (detecting patterns in visual data).\n",
    "\n",
    "> 🔑 **Note:** In deep learning, many different kinds of model architectures can be used for different problems. For example, you could use a convolutional neural network for making predictions on image data and/or text data. However, in practice some architectures typically work better than others.\n",
    "\n",
    "For example, you might want to:\n",
    "* Classify whether a picture of food contains pizza 🍕 or steak 🥩 (we're going to do this)\n",
    "* Detect whether or not an object appears in an image (e.g. did a specific car pass through a security camera?)\n",
    "\n",
    "In this notebook, we're going to follow the TensorFlow modelling workflow we've been following so far whilst learning about how to build and use CNNs.\n",
    "\n",
    "## What we're going to cover\n",
    "\n",
    "Specifically, we're going to go through the follow with TensorFlow:\n",
    "\n",
    "- Getting a dataset to work with\n",
    "- Architecture of a convolutional neural network\n",
    "- A quick end-to-end example (what we're working towards)\n",
    "- Steps in modelling for binary image classification with CNNs\n",
    "  - Becoming one with the data\n",
    "  - Preparing data for modelling\n",
    "  - Creating a CNN model (starting with a baseline)\n",
    "  - Fitting a model (getting it to find patterns in our data)\n",
    "  - Evaluating a model\n",
    "  - Improving a model\n",
    "  - Making a prediction with a trained model\n",
    "- Steps in modelling for multi-class image classification with CNNs\n",
    " - Same as above (but this time with a different dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data\n",
    "\n",
    "Because convolutional neural networks work so well with images, to learn more about them, we're going to start with a dataset of images.\n",
    "\n",
    "The images we're going to work with are from the [Food-101 dataset](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/), a collection of 101 different categories of 101,000 (1000 images per category) real-world images of food dishes. \n",
    "\n",
    "To begin, we're only going to use two of the categories, pizza 🍕 and steak 🥩 and build a binary classifier.\n",
    "\n",
    "> 🔑 **Note:** To prepare the data we're using, preprocessing steps such as, moving the images into different subset folders, have been done. To see these preprocessing steps check out [the preprocessing notebook](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/image_data_modification.ipynb).\n",
    "\n",
    "We'll download the `pizza_steak` subset .zip file and unzip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip file downloaded and extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# URL of the zip file\n",
    "url = \"https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\"\n",
    "\n",
    "# Specify the local file path where you want to save the zip file\n",
    "zip_file_path = \"pizza_steak.zip\"\n",
    "\n",
    "# Create a directory for extraction if it doesn't exist\n",
    "extracted_folder = \"pizza_steak\"\n",
    "os.makedirs(extracted_folder, exist_ok=True) \n",
    "\n",
    "# Download the zip file\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(zip_file_path, \"wb\") as zip_file:\n",
    "        zip_file.write(response.content)\n",
    "\n",
    "    # Extract the contents of the zip file\n",
    "    with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "    print(\"Zip file downloaded and extracted successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to download the zip file. Status code: {response.status_code}\")\n",
    "\n",
    "# Clean up: Delete the downloaded zip file if needed\n",
    "# Uncomment the following line to delete the zip file after extraction\n",
    "# import os\n",
    "# os.remove(zip_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the data (become one with it)\n",
    "\n",
    "A very crucial step at the beginning of any machine learning project is becoming one with the data. This usually means plenty of visualizing and folder scanning to understand the data you're working with.\n",
    "\n",
    "Wtih this being said, let's inspect the data we just downloaded.\n",
    "\n",
    "The file structure has been formatted to be in a typical format you might use for working with images.\n",
    "\n",
    "More specifically:\n",
    "* A `train` directory which contains all of the images in the training dataset with subdirectories each named after a certain class containing images of that class.\n",
    "* A `test` directory with the same structure as the `train` directory.\n",
    "\n",
    "```\n",
    "Example of file structure\n",
    "\n",
    "pizza_steak <- top level folder\n",
    "└───train <- training images\n",
    "│   └───pizza\n",
    "│   │   │   1008104.jpg\n",
    "│   │   │   1638227.jpg\n",
    "│   │   │   ...      \n",
    "│   └───steak\n",
    "│       │   1000205.jpg\n",
    "│       │   1647351.jpg\n",
    "│       │   ...\n",
    "│   \n",
    "└───test <- testing images\n",
    "│   └───pizza\n",
    "│   │   │   1001116.jpg\n",
    "│   │   │   1507019.jpg\n",
    "│   │   │   ...      \n",
    "│   └───steak\n",
    "│       │   100274.jpg\n",
    "│       │   1653815.jpg\n",
    "│       │   ...    \n",
    " ```\n",
    "\n",
    "Let's inspect each of the directories we've downloaded.\n",
    "\n",
    "To so do, we can use the command `ls` which stands for list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is New Volume\n",
      " Volume Serial Number is 3C97-A5CE\n",
      "\n",
      " Directory of d:\\Ineuron\\TensorFlow-\\notebook\\pizza_steak\n",
      "\n",
      "03-11-2023  15:00    <DIR>          .\n",
      "03-11-2023  15:00    <DIR>          ..\n",
      "03-11-2023  15:00    <DIR>          test\n",
      "03-11-2023  15:00    <DIR>          train\n",
      "               0 File(s)              0 bytes\n",
      "               4 Dir(s)  971,574,542,336 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls pizza_steak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we've got a `train` and `test` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 directories and 0 images in 'pizza_steak'.\n",
      "There are 2 directories and 0 images in 'pizza_steak\\test'.\n",
      "There are 0 directories and 250 images in 'pizza_steak\\test\\pizza'.\n",
      "There are 0 directories and 250 images in 'pizza_steak\\test\\steak'.\n",
      "There are 2 directories and 0 images in 'pizza_steak\\train'.\n",
      "There are 0 directories and 750 images in 'pizza_steak\\train\\pizza'.\n",
      "There are 0 directories and 750 images in 'pizza_steak\\train\\steak'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Walk through pizza_steak directory and list number of files\n",
    "for dirpath, dirnames, filenames in os.walk(\"pizza_steak\"):\n",
    "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way to find out how many images are in a file\n",
    "num_steak_images_train = len(os.listdir(\"pizza_steak/train/steak\"))\n",
    "\n",
    "num_steak_images_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pizza' 'steak']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('<U5')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the class names (programmatically, this is much more helpful with a longer list of classes)\n",
    "import pathlib\n",
    "import numpy as np\n",
    "data_dir = pathlib.Path(\"pizza_steak/train/\") # turn our training path into a Python path\n",
    "class_names = np.array(sorted([item.name for item in data_dir.glob('*')])) # created a list of class_names from the subdirectories\n",
    "print(class_names)\n",
    "class_names.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we've got a collection of 750 training images and 250 testing images of pizza and steak.\n",
    "\n",
    "Let's look at some.\n",
    "\n",
    "> 🤔 **Note:** Whenever you're working with data, it's always good to visualize it as much as possible. Treat your first couple of steps of a project as becoming one with the data. **Visualize, visualize, visualize.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
